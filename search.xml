<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Rust-2.错误处理]]></title>
    <url>%2F2017%2F12%2F04%2Frust-2%2F</url>
    <content type="text"><![CDATA[程序运行中，在执行一些操作时会出现问题，我们需要对这些问题进行相应的处理，这就是错误处理，错误处理可以有很多不同的方式和风格，下面来介绍一下Rust的错误处理。Rust的错误处理，严格来说算不上是一个专门独立的特性，而是某些特性带来的一种用法，但是其实用价值我觉得足以单独拿出来讲一讲。原计划这一篇会在这个系列比较靠后的地方出现，等前置的知识讲完，可以把这里的原理讲清楚之后。但是出于某些原因，我打算提前讲一讲。我们熟悉的错误处理首先我们来看一些C里面的错误处理。很多时候，我们使用返回值来判断一个函数的执行是否成功比如12345678910111213#include &lt;stdlib.h&gt;int main() &#123; void *ptr = malloc(1024); if (ptr == NULL) &#123; /* code */ &#125; else &#123; /* code */ free(ptr); &#125; return 0;&#125;或者使用Linux系统调用的时候123456789101112131415#include &lt;unistd.h&gt;#include &lt;errno.h&gt;int main() &#123; char data[128]; if (read(0, data, 128) &lt; 0) &#123; write(2, "Error when read from standard input: %s\n", stderr(errno)); // or perror("Error when read from standard input"); &#125; else &#123; /* code */ &#125; return 0;&#125;代码冗长有个很明显的问题，为了可靠地处理错误，必须在每个可能出错的操作后面加上错误的判断和处理，这就会造成代码中混入大量的错误处理。带来很多可读性上的问题：比如在阅读时，大量的无关逻辑会打断我们对主要逻辑的理解。不能保证被处理同时，正是因为代码的冗长，实际编程中我们经常在一些出错概率极小的操作后面省略错误处理，假设每次都能成功，然而这就埋下了很多隐患。虽然绝大多数情况没有问题，但是一但出现，那问题就是问题，不会因为其概率低而减轻影响。我们没有完全处理每一个错误，可以分两种情况讨论。一是使用同一个变量来同时代表错误和正常的返回值。这是一种非常容易混淆的代码，非常容易导致我们忘记检查，直接把表示错误的值当作正常的值处理。比如第一段代码，如果我们不经检查直接把NULL拿来使用的话，我们就能见到大名鼎鼎的段错误了；第二段代码，假如我们需要获取读取的长度，并且没有检查它十分合法，那就是把一个负数当长度使用，最后造成的问题也是非常诡异且难排查的。一是有些时候，真正要使用的值和错误是分开的两个变量，这种情况要好些，但仍然存在问题。比如第二段代码，如果我们需要使用的只有读取到的data，不用管返回的长度，那没有检查是否成功，data中的数据也不一定是我们所期望的，可能是未初始化的乱码，或者别的什么，直接拿来使用也会造成问题。风格不统一函数的编写者可以“自由”地决定使用返回值的风格，如何表示错误。使用的时候我们必要对这个接口有充分的了解，适应不同的风格。比如上面的malloc返回申请到的内存地址，NULL表示错误;read返回读取到数据的实际长度，使用-1表示错误。碰到一个不熟悉的函数，我们为了写出可靠的代码，都需要去仔细了解其接口。比如Linux的man page，不仔细阅读，里面有很多容易忽视的细节。同时不统一的风格也阻碍我们作出抽象，减少冗余的代码。“全局”的errno另外还有Linux的errno，大概是因为返回值太自由了可以各搞各的。所以他们设计一个类似与全局变量的errno（严格来说是每个线程各有一个，相互独立，但是在同线程内是全局的），来统一错误的处理，执行系统调用失败后，除了返回值告诉你失败了之外，还会设置一个errno变量指出具体的错误类型，然后可以通过stderr拿到解释对应错误的字符串，或者通过perror直接打印出来。但是errno只能表示最近一次的错误，如果有一个错误导致另一个错误的这种错误链，errno是无法表达的。而且任何库和用户代码都能自由修改errno，除了直接调用系统调用可以勉强相信有代码质量和规范的保障之外，你无法保证拿到的errno的值一定是有意义的。而且可读性上来讲，可以用返回值，局部变量解决的事情就尽量避免全局变量，它不能在小范围的上下文中迅速看出来龙去脉，是突然冒出来的东西，会给不了解的人带来很多困惑。回到正题看了上面之后，我们希望的错误处理是什么样的呢？风格统一，不易错误使用写起来方便简洁还有一些细节的注意点：不要把错误储存在全局变量里不用用一种类型的不同区间表示两种不同的东西最好也不要把返回值和错误分成两个独立的变量Union Type细节的后两点看起来是矛盾的，我们既不能用一种类型同时表示正常返回值和错误，又不能把它们分开成两个变量返回，那要怎么做？这就可以说到一种在程序语言学里面被成为Union Type的特性。这就是我们要讲到的Rust的错误处理的核心。Rust里面可能出错的操作的返回值一般为如下的Result类型。1234enum Result&lt;T, E&gt; &#123; Ok(T), Err(E),&#125;以上的类型声明表示，Result类型下分两个子类型，Ok代表正常的返回值，Err表示返回错误。同时这是一个泛型结构，虽然我们还没来得及讲到Rust的泛型，但是这种常见的特性大家应该都是了解的。这里是一个统一的接口，T和E可以被替换成各种类型，比如File::open函数的返回值类型就是Result&lt;std::fs::File, std::io::Error&gt;，可能返回一个打开的文件对象，或者一个IO错误。这种在学术界被叫做Union Type，在Rust里面叫enum的东西，其实和C里面的union和enum都不同。C里面的union表示多个类型共享一块内存，可以对这块内存使用多种解读方式，具体按哪种类型解析还是需要程序员自己理解上下文来正确使用。如果用C来模拟Rust里面的enum，大概长是这样的123456789101112enum type_result &#123; OK, ERR,&#125;struct result_open &#123; enum type_result type; union &#123; File *ok; int err; &#125;;&#125;实际使用的时候，我们需要做如下判断123456789switch (result.type) &#123;case OK: /* do something with result.ok */ /* but result.err can be used when it shouldn't be */ break;case ERR: /* do something with result.err */ /* but result.type can be used when it shouldn't be */&#125;而在Rust里面，写起来更自然一点。而且语法上限制了，如果它是错误，你就不能把它当正常的返回值解释，反之亦然。12345678match result &#123; Ok(file) =&gt; &#123; /* do something with file */ &#125;, Err(e) =&gt; &#123; /* do something with e */ &#125;,&#125;更深入本质一点讲，这种接口把判断操作成功和取得返回值两个操作合为一体，杜绝了没有判断操作是否成功就直接把返回值拿来用的情况。如果想看偏原理一点的，到这里就结束了，我们已经保证了错误一定会被处理。然而，如果关心错误处理的实际操作，想看如何简洁方便地处理错误，目前为止都还是铺垫，下面才是真正的好戏。if let语法糖上面的match语句在大多数时候写起来还是太长了。所以Rust从Swfit那边学过来一种语法，作为match的语法糖。123if let Ok(file) = result &#123; /* do something with file */&#125;等价于123456match result &#123; Ok(file) =&gt; &#123; /* do something with file */ &#125;, Err(_) =&gt; &#123;&#125;,&#125;或者123456if let Ok(file) = result &#123; /* do something with file */&#125;else &#123; /* do something without e */&#125;等价于12345678match result &#123; Ok(file) =&gt; &#123; /* do something with file */ &#125;, Err(_) =&gt; &#123; /* do something without e */ &#125;,&#125;前面一种如果操作失败，则什么都不用做。后面一种拿不到具体代表错误的那个值，只能对所有的错误情况做统一处理，但是写法比原先简洁了些。不过还是不要急，后面有更好的。?操作符终于来到了本篇的关键。Rust中基于Result，又搞出了一个?操作符，。用于一种非常常见的场景，我们不马上对错误进行处理，而是直接把错误返回上一层。12345678910111213141516171819202122use std::fs::File;use std::io::&#123;BufRead, BufReader, Write&#125;;use std::path::Path;fn copy_file&lt;P: AsRef&lt;Path&gt;&gt;(path_src: P, path_dst: P) -&gt; std::io::Result&lt;()&gt; &#123; let file_src = File::open(path_src)?; let mut reader = BufReader::new(file_src); let mut file_dst = File::create(path_dst)?; loop &#123; let content = reader.fill_buf()?; if content.is_empty() &#123; break Ok(()); &#125; file_dst.write(&amp;content)?; &#125;&#125;fn main() &#123; copy_file("/tmp/src", "/tmp/dst") .unwrap_or_else(|e| eprintln!("&#123;&#125;", e));&#125;这里举例用Rust实现了一个复制文件的函数。main函数尝试调用这个函数，失败则打印错误信息。我们主要关注copy_file函数，可以看到其中有4个?，这表示代码中有四个位置可能失败，打开输入文件，创建输出文件，读文件，写文件。这四个操作的返回类型都是Result&lt;T, E&gt;，可能为子类型Ok(T)或者Err(E),如果其中任何一个操作失败，即返回类型为Err(E)，函数会立刻将Err(E)返回上一层；否则Ok(T)中的T会被取出，函数继续往下运行。这里如果某个操作出现错误，则直接将错误返回上一级这个操作，直接被简化为一个?。我们可以说，没有任何无关代码，来干扰我对主要逻辑的理解，这一目标已经几乎完美地实现了。大家可以想象一下，这一段如果用C来写，并且要求可靠地将所有错误都处理了，需要往里面插入多少额外代码。总结先讲到这里，其实还有不少可以讲，比如Result还可以使用函数式风格的Monad处理错误即使这样的接口仍然需要注意的问题定义自己的错误类型以及?操作符的进一步扩展这些内容可能会更新在本篇或者另开几篇继续说明。]]></content>
      <categories>
        <category>编程语言安利</category>
        <category>Rust</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>Rust</tag>
        <tag>错误处理</tag>
        <tag>Monad</tag>
        <tag>Union Type</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈谈代码风格]]></title>
    <url>%2F2017%2F12%2F03%2Fcode-style%2F</url>
    <content type="text"><![CDATA[这次先不说具体技术，讲讲我对代码风格的看法吧。实际上代码规范说明也不少，但是都有很多，一条一条比较细地列下来，但是比较乏味，背后的道理讲得也不够详细。我就打算选取少量个人觉得重要的点，详细地讲一讲，希望能有趣一点。所谓好的代码，就是易维护的代码，易维护的代码需要易读，易修改；其中易读是基础，不易读怎么能易修改，本次就重点讲讲易读的代码。命名和作用域有意义的变量及函数名使用有意义的变量及函数名，可以显著地提高代码的可读性，我觉得好处大家都懂。具体的做法上呢，我们不要害怕函数和变量名太长，现在的IDE和编辑器都能提供代码自动补全的功能。使用缩写一定要使用通用的，大家都承认的缩写，没有的话宁愿写很长的全称，让大家一看就知道是什么；如果不开源的话，只要自己公司或部门能看懂也可以接受。再比如一般不应该在名字中出现数字表示函数的两个版本，比如add(x, y)和add2(x, y)，如果确实有必要分成两个函数，应该在函数名上让明确其具体区别，比如add_integer(x ,y)和add_float(x, y)，不需要逼读者去了解实现。当然也有一些例外，比如函数名中的数字确实和函数的具体区别相关比如add2(x, y)和add3(x, y, z)表示相加的数字个数不同，是可以接受的。有些地方用2来谐音表示to，也勉强可以接受（个人觉得这个还是不要提倡）。多使用中间变量简化复杂表达式多使用中间变量，能够有效控制代码每行的长度；把复杂表达式分解成一个个简单表达式，更能帮助理解。同时，有意义的中间变量名能进一步把整体流程解释清楚。变量作用域尽可能小对于局部变量，我们应该尽量能够做到，一眼看去，变量的整个生命周期一览无余，包含其声明及每个使用的地方。这样我们能够非常有自信这个变量从哪里来，到哪里去；没有被意外修改，可以放心地使用；同时也不会误会它可能在未来被使用。不要重用变量不要重用变量，属于变量作用域尽可能小的一个具体细节。重用变量显然是无必要地增大了变量的作用域，容易造成混淆和误用。最好分开定义，能够清晰看出它们毫无关系。一个非常常见的场景是，用途近似甚至相同的变量，比如循环变量，经常有人喜欢重复使用同一个；这里我们应该把作用域隔离好，之后使用同样的变量名也是可以接受的。局部变量名尽量简短这个看起来和前面有意义的变量名有矛盾。但是我们需要注意这里是局部变量，而且我们提倡作用域尽可能小，在这种情况下其上下文是一目了然的一小段，如果我们能快速根据其近距离的上下文判断其含义，就不需要用过长的变量名扰乱视线。1234567bool successInPing = ping("8.8.8.8");if (successInPing) &#123; /* code */&#125;else &#123; /* code */&#125;如以上代码，其中successInPing这个名字就没有必要，从上下文可以非常轻易地看出这个变量指ping的返回值，我们只需要success，就能很清晰地看出这是指ping是否成功。123for (int i = 0; i &lt; n; i += 1) &#123; a[i] = b[i];&#125;再比如由于i同时是iterate和index的首字母，所以使用i作为循环变量和下标已经非常普遍，约定俗成了，也是可以接受的。模块化大家都知道好的代码要模块化，那如何模块化？其实编程语言给我们提供了最基础的模块化单元，就是函数。函数就是最重要的模块化手段，没有之一；利用好函数，其他的模块化都是锦上添花；函数层面没模块化好，其他什么都是白搭。模块化能减少代码重复，提高复用率，符合DRY(Don’t repeat yourself)原则；减少重复也是提高可读性的途径之一。多提取帮助函数和提取中间变量，简化复杂表达式一样。我们同样可以通过提取帮助函数简化复杂的处理逻辑，提高可读性。提取函数的时候，不管多短，只要是一个重复使用（甚至暂时还没有重复）的基本功能的单元，哪怕只有一两句也可以提取成函数，有这样的认识，我们会发现，代码里面的重复比我们想象还要多些。一个函数只做一件事一个函数只做一件事情，其实可以有效地帮助代码复用，越是把函数拆分提取成小的基本功能单元，它就越是通用，越能在自由组合后用于更广泛的地方。短小的函数多提取帮助函数，一个函数只做一件事情，那我们自然就得到了很多短小的函数。而且短小的函数和前面讲的变量作用域尽可能小也是一致的。都能帮助一目了然地看明白整段逻辑。而且函数本身也是个作用域，短小的函数能帮助，某些生命周期不得不贯穿整个函数的变量，缩小作用域。函数的一般没有严格的硬上限，但是一般大致的软上限在四十行左右，主要来源于，屏幕不用拉动能一次性显示的代码行数。避免使用全局变量传递信息除非必要，不要使用全局变量传递信息。一旦使用了全局变量，函数就具有了状态，不再对确定的输入有唯一确定的输出，而是依赖于这个全局的状态，而这个全局的状态可能被任何地方修改，使代码的正确性更难保证；同时单元测试也变得难以编写。使用全局变量传递信息的这几个函数也被耦合在一起，而仅通过参数传递进行信息传递的函数可以自由地组合使用。注释自解释的代码代替注释经常看到提倡程序员写注释的说法，其实注释并不是越多越好。良好的代码本身应该是自解释的，如果需要很多注释来说明，往往代码本身是糟糕的。如何写自解释的代码，其实方法在前面都讲到了。多使用中间变量，有意义的变量名自然就代替注释进行了解释；多提取帮助函数，有意义的函数名也代替了注释进行解释。仍然需要注释的地方为了性能使用了一些底层操作或复杂算法各种原因导致的一些不得不存在的丑陋代码或奇技淫巧函数的参数和返回值说明，特别是具体调用示例可以更清晰快速地说明一个函数的使用整个模块的总体介绍，架构思路，存在原因等不要过分容错在编程中程序会碰到各种各样的错误，需要继续错误处理或者说容错。但是错误并不都一样。有些错误是由于IO等需要和外部交互导致的，无法避免其失败的可能性，必须进行处理。有些错误是属于代码的逻辑错误，如果程序本身是正确的，根本不应该出现，这种情况，其实并不应该容错。一个非常普遍的例子就是空指针，其实很多时候，函数的输入参数是一个指针，按正确逻辑根本不应为空，要是在C++里，我们可以直接使用引用，让类型检查来帮助我们保证不会出现空指针，但是C里面没有这种功能，有时候我们就人为进行容错。接受到本就不该出现的空指针后，这个函数本身又返回一个值表示错误，一般也是空指针，然后空指针的影响在程序中扩展开来，等最终发现空指针导致的问题后，我们已经很难定位到问题的源头。其实正确的态度是，强硬地不接受这种调用代码逻辑问题导致的错误输入，直接让程序崩溃就好了，这就是一个需要马上发现修复的问题。当然空指针和函数传入错误参数都只是举例，实际上强硬对待所有逻辑错误的场景不止这些。有时候我们把把程序崩溃看得过于严重，实际上真正在工作环境崩溃才严重。让程序强硬对待错误，易于崩溃，其实是让错误更易于在开发测试阶段发现，从而更少地把Bug流到实际工作环境才发现，一则含有Bug行为出现错误的程序严重程度未必就低于崩溃，二则这种处理后真正到工作环境的崩溃搞不好反而更少。同时，还能防止错误在代码中扩散，变得难以追踪；帮助快速定位问题的源头，进行快速的修复，节约大量排查的时间。这就是”fail fast”思想，一旦发现问题，就让软件尽可能快，尽可能显眼地失败，实践证明是一种能显著减少代码bug数量的技术手段。写”愚蠢”的代码良好的代码，往往是简单有效的代码，是不耍小聪明的代码。这就是鼎鼎大名的KISS(keep it simple stupid)原则。运算符优先级充分利用运算符优先级，无非能少打几个括号，没有有效的好处，反倒在过度依赖优先级的情况下会严重影响可读性，省略括号后大多的人不清楚运算顺序。正确的态度是不需要记忆复杂的运算符优先级，也不要让以后的读者需要陪你一起来了解这种东西，不确定就加括号。当然这个问题我在实际工作中看到不多，在学校的教材和考试里面比较多见。宏C的宏本质上属于代码在文本层面上的替换，如果你见识的语言特性够多的话，应该能认识到这是个功能有限，又容易出错的东西。功能有限解释起来麻烦，这里就先不解释了，以后有空介绍一些其他语言中也叫宏，但是比C宏强大得多的东西（当然它们都有个统一的特点是用起来很爽，但是定义实现复杂且可读性差，都不建议滥用）；以及C里面需要用宏实现的功能，在其他语言里用更易用不易错的特性也可以做到。容易出错方面，一是它没有函数的类型检查对正确性进行一定地保证，二是难以直观地看出文本替换完之后代码到底会变成什么样。但是客观地说呢，由于C语言本身在特性上的缺乏，恰当地使用宏确实能弥补一下这个问题，减少一些代码重复（经常是人为地想要绕开类型检查，写一些类型通用地操作），在一定程度上让代码简洁可读。可以考虑使用宏的场景，例如在一定程度上模拟范型，用宏实现类似于泛型函数或泛型结构；例如用宏模拟迭代器，方便地遍历链表，哈希表等结构。完全不应该使用宏的场景包括，定义常量，强制内联等。自增自减自增自减操作符其实就是一个失败设计，一开始就不应该存在。自增自减操作符鼓励程序员使用其返回值，把两个操作合为一个语句，同时由于增加减少变量这个副作用的发生时间到底在前还是在后，又搞出两个版本的自增自减，增加使用者心智负担。更严重的是在一个复杂表达式里面对同一个变量进行多次自增自减是未定义行为，即语言标准没有规定其求值顺序，在不同编译器甚至同一个编译器的不同版本里面可以有不同行为，换句话说，根本不应该用，但是在语法上它是合法的。从可读性上来讲，增加减少变量作为一个操作，读取使用这个变量应该作为另一个操作才是正确的，其顺序能更加自然且显然地通过语句地顺序展示。我个人地习惯是使用x += 1代替x++或++x，一个原因是+=这个符号本身相对可以提供一种它没有返回值的心理暗示（虽然绝大数语言是有的）有些人觉得自增自减比分开来写快，然而代码和生成的机器码又不是一一对应的。还有些人觉得++i效率高于i++，因为分别等价于({i += 1; i;})和({int tmp = i; i += 1; tmp})。我觉得他们应该去看一下一种编译优化叫做死代码消除。写编译器的人又不是傻子，几十年前技术不完善的时候确实一部分观点是属实，也因此发展出一些奇技淫巧，但是随着时代的进步，这些早就成了历史，然而有些人现在还相信其有效性。没有遗漏的分支有时候多层嵌套分支的时候，我们容易漏考虑一些情况。如何减少这种情况，尽可能写出没有遗漏，无懈可击的分支判断。其实诀窍在于宁愿有小的重复，尽量不要省略任何一个else分支。如果依赖于把某些分支的公共逻辑放在分支的后面，让所有应该执行公共逻辑的分支掉下去，逻辑复杂后就越难梳理出哪些情况掉下去了，容易造成逻辑的错误。当然你要是说有时候这样些重复部分太长了，代码很冗长怎么办？其实我前面早就说过了，提出去做成函数。可借助编译器的特例还有一个特例，如果已经到函数结尾了，每个分支都会直接返回一个值结束函数。这种风格还能借助编译器来检查。如果你的编译器足够成熟或版本够新的话，就应该有完善的分支流程分析。它能告诉你这段代码可能遗漏了返回。12345int foo() &#123; if (condition()) &#123; return 0; &#125;&#125;这段代码的return 2是无用的死代码。123456789int foo() &#123; if (condition()) &#123; return 0; &#125; else &#123; return 1; &#125; return 2;&#125;那么我们不要在函数末尾加上哨兵return，这也可以被认为是多个分支的共同逻辑，所有return放在分支里可以让编译器帮助我们判断分支是否遗漏。假如我的意图如下。12345678910111213int foo() &#123; if (condition1()) &#123; if (condition2()) &#123; return 1; &#125; else &#123; return 2; &#125; &#125; else &#123; return 3; &#125;&#125;漏写成这样就能被编译器提醒有个分支没有返回值。12345678910int foo() &#123; if (condition1()) &#123; if (condition2()) &#123; return 1; &#125; &#125; else &#123; return 3; &#125;&#125;写成这样编译器就只能当它是正常的，然而这仍然和意图不符，是错误的逻辑。12345678int foo() &#123; if (condition1()) &#123; if (condition2()) &#123; return 1; &#125; &#125; return 3;&#125;小结关于编译优化我们认识并善于利用编译器的能力，这也是用自动化代替人工的一种。高级语言就是为了人类能够更加方便地表达计算逻辑而出现的，人类只需关注代码对自己友好，除了高层逻辑以外的优化交给编译器才是应有的思路。虽然由于现实的技术水平限制，编译器还不能完全理想地达到我们的目标，其实以及远比很多人认为地强大了。有些自以为是的优化，其实除了降低可读性，提高出错率之外毫无用处。真想要进行一些偏底层地优化的话，与其瞎折腾，不如先去了解编译器优化，了解编译器做不了什么。即使你真的对编译器有一定了解，你也会发现，除非你在一个非常冷门的硬件架构上开发，或者使用的编译器不够成熟，否则底层优化少上较少会有你发挥的余地。编译优化涉及大量收益和代价的权衡，虽然编译器是按照死板规则的程序，但是这些规则好歹是很多专家花费大量时间精力总结出来的，不是那么容易就能做地更好的。编译优化展开来讲可以造就一个博士，我的了解也没那么多，这里就大概概述一下，以后可能会专门写几篇文章，进行稍微详细些的介绍。编译优化可以这样定义，编译优化就是编译器尝试去最大化或者最小化一个可执行文件一些属性。最常见的需求是最小化运行时间；稍微少见一点的是最小化存储使用；近些年移动端的兴起带动了最小化耗电量的需求。当然前提是程序的行为不能有变化。为了达到优化的目的，其方向大概有更少的代码（指生成的代码，一般是机器码），更少的分支（或跳转），对分级存储的利用，并行化（对偏底层的语言主要是指令级，存储级的并行），提高访问局部性，用快速或简单的指令代替缓慢或复杂的指令等。编译器分析代码后，常常会形成SSA（static single assignment form，静态单赋值形式），不管我们使用多少中间变量，是否重用变量，其实其SSA是完全相同的。通过算法分析后，进行的寄存器分配和内存分配，其实和原本代码里声明的局部变量数量没有什么关系。经过条件常数传播，全域数值编号，死代码消除后绝大多数的多余操作都被消除了。另外编译优化的一个重头戏是循环优化，有统计数据证明程序的大部分时间跑在循环里，循环优化一点，整个程序性能就能提高一大截。分支判断和循环有些重叠，都是需要靠分支和跳转实现，而且分支预测失败也是对性能影响也不小。编译器既可能把一个循环拆成多个，把多层循环地里外层互换，提高访问的局部性；也可能把多个循环合并成一个减少循环本身的分支代价；或者展开循环减少循环次数同时提高指令级并行。简直是各种捏扁搓圆地变换。函数内联方面函数本身指令数量小于等于函数调用需要额外增加指令数量的，以及只调用一次的函数都是内联了只有好处没有坏处的可以无脑内联，但是其他的情况就要考虑各种权衡，同一个函数在不同的调用处是否内联甚至是分开考虑，进行不同处理的。看到这里大家还觉得我们有能力且应该替编译器做决定吗？还要为之付出可读性的代价吗？关于代码简短另外，我们说代码优雅简洁并不是单纯从字符数量或行数上的短小。我们应该通过减少重复，简化逻辑来达成代码的逻辑层面上的简洁；不要滥用一些特性，盲目追求周期语法层面的简洁。其他统一规范在项目不是只有一个人进行开发的时候，统一规范相当重要的，即使这可以不算在代码质量。统一编码在项目中，大家往往喜欢使用自己的母语进行注释，但除了英语之外的语言由于历史原因，有各自杂七杂八的不同编码方式。如果不统一编码，就会造成经常打开代码后看到注释全是乱码的问题；更严重的是代码在使用不同编码的人手上转了一圈，修改保存好几次之后，可能会变成彻底的乱码，用啥编码都看不到原来的注释写的是什么了。如果你觉得自己英语水平还可以的话，干脆全部注释使用英语写是避免编码问题的好办法。不然，我们最好就统一编码，当前业界绝大多数地方都统一使用UTF-8编码，它的好处：一是包含了几乎所有语言的字符，不像过去的各种编码，每个语言都有各自的标准，不同的语言间的编码是互相重叠冲突的；二是这是一种变长编码，原来ASCII码中的英文字符和常见符号仍然是一个字节，而其他字符可能是两个或这三个字节长，对于主要是英语的文本来说，长度短于每个字符固定两个字节长的编码。统一缩进在一个项目中，不同的人使用了不同的缩进，很可能造成打开代码发现缩进没有对齐，虽然对逻辑没有影响，但是缩进的视觉效果对人类理解代码的层级还是非常重要的。缩进主要有两个分歧点，一是使用Tab还是Space，二是缩进的长度。Tab的一个好处是可以避免第二个分歧点，如果我们所有的缩进的严格使用Tab，则不同的人想要把缩进长度显示为几格都没有关系。Space的一个好处是，有的时候我们有很长的条件表达式，希望换行并对齐以获得更清晰的结构，但是这个时候对齐需要的缩进不一定能能被正常缩进的单位长度整除，就比如如下例子中默认缩进是四个，但是对齐需要六个。这里Tab就无法做到这样的效果，或者即使对于编写者使用Tab对齐了，其他人换个长度来显示Tab仍然没对齐。12345while (long_condition1() &amp;&amp; long_condition2() &amp;&amp; long_condition3()) &#123; /* code */&#125;这两者最大的区别是，Tab缩进允许不同的解释，相对自由，但是可能由于某些原因，导致换个显示长度就破坏了原作者的意图；Space缩进对所有人看起来都是一样的，相对不自由但是严格。到底使用Tab还是Space其实不重要，重要的是要统一。不过其实业界大多数地方是四个空格缩进的，顺便一提，四个空格缩进不是让你打字的时候每次按四下空格，你应该配置你的IDE或编辑器在按Tab键的时候自动扩展成四个空格。]]></content>
      <categories>
        <category>闲言碎语</category>
      </categories>
      <tags>
        <tag>代码风格</tag>
        <tag>编译优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C的设计失误]]></title>
    <url>%2F2017%2F02%2F08%2Fbad-design-of-c%2F</url>
    <content type="text"><![CDATA[日常使用中，可能不时觉得某些编程语言里面有一些不好用的地方。当然大多设计都同时有优缺点，我们要理解其中的权衡。 不过以现在的眼光来看，以前有些设计的缺点明显大于优点，这就不能完全推脱为权衡，而可以称之为设计失误了。当然两者的界限不太分明，见仁见智，这里就谈谈我的看法。我准备总结并吐槽一下我平时使用过的一些编程语言的种种设计问题。当然不是为了批评，有些语言是在几十年前设计的，在当时缺乏足够的实践教训和前人经验（或者是缺乏经验导致的不重视设计细节）的情况下，这些问题都是情有可原的（不过某些所谓现代语言仍然继承了，甚至自创了一些设计失误就值得批判了）。总结这些设计失误，一是引起重视，帮助我们在使用中尽量避免一些问题，二是帮助我们理解一些现代语言为何采取了不同的设计。这里，就先从大名鼎鼎的C开刀（设计并不全部由C首创，但是起码照搬了没改，同时也影响深远），有些在新标准里面有所改善。另外考虑到C的年龄，从缺乏特性挑刺有点欺负人，这点就尽量不谈。变量默认可变声明变量默认是可变的，声明不可变变量需要额外加上const进行修饰。我们要知道内存及线程不安全的根源是共享和可变性的共存。而当确定一个对象不可变时，我们就可以放心地共享它，同时方便编译器进行更彻底的优化。默认不可变更有利于程序的安全性。默认不可变时，如果我们修改了不可变变量，就会被编译器警告，我们确认是否真的需要这个变量可变，然后进行修改；变量默认可变的情况下，我们经常将不需变化的变量声明为可变的，编译器并没有什么意见，如果误改了不应该变化的变量较难发现。实际使用中，需要变化的变量并不显著多于固定的变量，特别是我们鼓励多使用中间变量提高可读性的情况下，不需变化的变量就更多，同时编译器的优化也能保证更多的中间变量并不会增加存储空间和性能的消耗。从以上原因来看，可变和不可变中，如果要选择一个作为默认，有什么理由选择可变呢？另外有些语言里也有可变与不可变地位平等，没有哪个是所谓的默认，比如val声明不可变，var声明可变。当然，基于以上理由，个人还是更倾向默认不可变。基础类型偏执其实这里讲的问题严格上不是基础类型偏执，但是对这个问题我没有找到合适的专有名词。基础类型偏执，是指某些人偏好并尽可能使用基础类型，而不是定义一个新类型进行抽象，从而影响可读性和可重用性；主要是针对程序员编程的时候，偏向于使用基础类型，而不是构造复合类型。我这里讲的主要针对于语言设计的时候把不同用途的东西归于一个类型。严格来讲这是两个不同的问题，但是其背后的思想是相通的，带来的危害几乎是相同的。所以这里就当它也是基础类型偏执。Type-rich Programming先讲讲基础类型偏执的反面，有一种叫Type-rich Programming的思想。Type-rich Programming大概就是把不同单位和用途的东西用不同的类型表示，充分利用语言自身的类型系统，在编译期进行更多检查，便于开发时就发现更多隐藏的错误。比如下面这个比较极端的例子，就有效防止了年月日都是整数类型而把参数顺序写错。虽然例子不太靠谱，这也说明了Type-rich Programming的一种应用。1234567891011121314struct Year(usize);struct Month(usize);struct Day(usize);fn print_date(y: Year, m: Month, d: Day) &#123; let Year(y) = y; let Month(m) = m; let Day(d) = d; println!("&#123;&#125;-&#123;&#125;-&#123;&#125;", y, m, d);&#125;fn main() &#123; print_date(Year(2017), Month(9), Day(12));&#125;我们无视上面这种可以把程序员累死的风格，下面讲点实际的东西。回到CC（特别早期的C）里面有一种倾向，只要底层实现相同，则可以归为一种类型，比如没有单独的bool类型，8位整数和字符是一种类型。类似的思想又带来了C接口上的一种惯例，当概念上需要多个类型时，使用一个基本类型，并把多种类型映射到它的不同值区间，比如0表示正常，负值表示错误；空指针表示错误，否则正常。虽然从功能上没什么损失，但是降低可读性，同时更容易造成人为的编码错误。没有独立的bool类型就拿没有单独的bool类型来说，C最开始没有专门的bool类型，任何类型都可以当作bool，二进制表示非零则认为是true，全零则认为是false，最常见的是使用整型作为bool使用。不小心就可能把一个有其他含义的数值当成bool使用。比如比较函数，使用小于0，等于0，大于0的整数分别表示小于，等于，大于。要比较两个对象相同，可以这样123if (cmp(a, b) == 0) &#123; /* code */&#125;但是一不小心，写漏了返回值的判断，变成123if (cmp(a, b)) &#123; /* code */&#125;乍一看没啥特别不对的地方，编译器也没什么异议，直接把返回值当bool类型用了，并不知道它是别的含义，相信不少人写过这种bug。如果有单独的bool类型，供条件语句使用，同时不允许整数到bool的隐式转化，这里编译器就能纠正你，cmp(a, b)返回的不是一个bool类型，所以不能作为if后面的条件使用。虽然C后来的标准中加入了bool类型，但是由于兼容性原因，整数仍旧可以被隐式转化为bool，仍不能防止误用；值得欣慰的是GCC 7.0会对此有警告，然而实际生产环境基本没有地方会用这么新的版本，一些历史代码使用整型表示bool也需要大量的修改。当然这里的问题不只是bool，其实比较函数的返回值应该定义一个enum，也不该是整数。不过说起来C的enum也不够到位，只是对整型的简单封装。字符和字符串C里面一开始char就是一个8位整数，因为当时他们觉得ASCII字符和8位整数本质上就是一样的；另外字符串就是char的数组。于是后来需要支持各种语言的各种奇妙字符时，就发现需要定义两字节的宽字符类型，而不能复用char。再后来，大家开始使用Unicode的时候，字符串都不能用字符数组来表示了，因为Unicode字符都未必等长，必须搞个专门的字符串类型了，而这其实一早就该抽象出来。没有根据用途定义不同的类型，就造成场景变化后无法重用，这就是个典型例子，如果把字符和字符串这种用途上不同的就抽象为专门的类型，起码能够自然地在扩展时达到代码的重用（当然对C来说，就算复用代码，编译出的库也不能复用，并不能完全兼容）。空指针虽然很多人可能没有意识到，空指针也是基础类型偏执的一种。空指针的设计属于，把多种不同的类型，映射到同一类型的不同值区间。这里其实是说，空指针和真正指向正确目标的指针，应该是两种不同的类型。因为类型应当是相同行为的值的一个集合，而这两种指针的行为并不相同。解引用一个正常指针能得到一个值，解引用一个空指针，在C标准上来说是未定义行为，在实际实现中一般是段错误。空指针这么多年来带来了不计其数的bug和经济损失，连其发明者都称之为”billion dollar mistake”。至于把空指针作为一种类型的设计到底是如何操作的，之后会在另一篇文章介绍。副作用返回值共存的运算符C中有++和--这样的自增操作符，经常被人滥用，只为了写出简短的代码。未定义的求值顺序一旦我们在同一个表达式中使用了多个自增操作，像x++ + ++x，其求值顺序就属于未定义行为，在不同编译器实现中可以不同。所谓未定义行为，就是从规范上不应该出现的行为，标准没有规定。碰到之后编译器干任何事情都是符合标准的（比如编译出人工智能程序接管你的电脑；再比如通过啥恶意代码把你的硬件烧掉一些啥的（当然符合C标准不代表合法））。据说GCC的早期版本有个彩蛋，在遇到未定义行为时会尝试打开机器里的某些游戏（真是温柔）。更糟的是，曾有人堂而皇之地把这种代码写进教科书，并一本正经地分析其求值顺序，流毒甚远。返回值造成的另一个问题赋值语句具有返回值，于是我们可以写x = y = 0。看起来比较方便，但是同时也可能出现123if (x = 0) &#123; /* code */&#125;这样的误用，if的条件语句中判断相等的==少打成=，但语法仍然是合法的（这有两个问题，一是赋值根本不应该有返回值；另一个是前面提到的整型不应该隐式转化为bool类型用于分支判断）。这一类问题的根源在于不必要地追求语法的短小（短得有限，而且分开两句写逻辑可能更清晰），同时具有副作用和返回值的运算符完全不必要，还容易出错。x++完全可以使用x += 1或x = x + 1代替，虽然后面两个式子同样具有着返回值，但是看起来更像单纯的赋值，更容易给人不去使用其返回值的心理暗示（当然最好能直接去掉其返回值，虽然为了向下兼容这是不可能的）。所以，我一般在使用C的时候，使用+= 1，-= 1代替自增自减，这样更能提醒自己不去使用其返回值。简陋的宏变换宏其实就是编译阶段对代码的变换。C的宏的实现方式为字符串替换，作用于词法分析之前。过于简单粗暴，容易出错，功能也有限。这样的宏不是清洁宏，宏里面使用的中间变量可能污染作用域，恰好外面也使用相同变量名的话，就可能导致奇怪的行为。另外一般使用的时候，我们心理上容易把宏当成和语句或函数差不多的东西，但是实际上一个类似于#define foo } else {或者#define bar ); sth()的宏的实际行为能完全超出你的预料之外。仔细一想我们发现，这个问题和SQL注入的原理简直一模一样。如果我们了解宏的问题所在，使用时尽量谨慎，其危害还是可控的，毕竟代码是在自己控制之下的，该变换的在编译时都确定了。不像SQL需要在接受并拼接外部的输入后，再进行语句的分析。但一个很大的问题就是，并不是很多人都能意识到这个问题，谨慎地使用宏。不少C程序员会滥用宏，还引以为傲，颇为得意。不少使用宏的地方都可以使用内联函数，全局常量替代，而且相信编译器，这几乎没有性能或内存的代价。另外一部分问题是，有的时候我们想减少重复代码，发现不用宏无法实现。其主要原因是由于C没有泛型或函数重载，比如可作用于所有可比较类型的max函数，就需要通过代码变换来绕开函数的类型限制。宏并不是什么必需的功能，当然宏也是个有用的语言特性，可以是对语言功能的有益补充，但是需要好好考虑宏的设计（当然这个问题很复杂），比如考虑是对抽象语法树进行变换而不是对字符串进行变换，宏变换只能影响到自己内部，不会对语法树的上层造成影响之类的。分号空语句允许单独的一个分号;作为空语句存在的语法。于是有时没注意，可能出现这样的代码1234while (true);&#123; /* code */&#125;while (true)后面的;被视为空语句，并被作为循环体，结果进入了空语句循环，真正要循环的代码被遗弃在一边。大概有两种解决方案禁止使用分号作为空语句，真的需要空语句的地方，使用一对大括号{}完全可以达到要求，不易手滑写错也更加显眼要求if,for,while后面跟随的必须是语句块而不能是单个语句（循环和条件语句后面只有一句语句的时候可以省略大括号，本来就是一个编码隐患，要求if,for,while后面必须跟随不省略大括号的语句块这一点被写进了不少编程规范中，其实不如干脆在语言语法中要求）switch默认fallthroughswitch语句中的每个case，结束的默认行为是fallthrough，继续运行下一个case，也是一个潜在的bug制造点。这一点很反直觉，而且绝大多数情况我们都需要返回。不少现代语言都已经改变其默认行为返回。那么C为什么一开始采用如此奇怪的实现方式呢？我估计主要是多种可能取值属于同一种情况的时候12345678switch (cond) &#123; case 1: case 2: /* code */ break; case 3: /* more */&#125;这里由于case 1往下走了，才能和case 2共用一段代码。如果要改为默认返回的话，就需要额外声明case 1需要fallthrough。这是我对C为什么这样设计的猜测，不过个人挺奇怪为什么这么解决，我觉得有个更好的解决方案，就是支持一个case包含多个值的语法，比如123456switch (cond) &#123; case 1, 2: /* code */ case 3: /* more */&#125;这样就比较自然。当然语言为了向下兼容，不能乱改，另一个比较实际的解决方案是GCC 7.0对每个case结尾没有break会有警告，除非我们在case结尾的位置使用__attribute__((fallthrough))属性标注或类似与/* Fall Through */的注释才能消除警告。说起来GCC的新版本不断增加新的警告，所以我见过有些编译选项里写了-Wall -Werror的项目升级编译器版本就直接各种编译失败了。八进制整数字面量以0开头的整数字面量被识别为八进制，想必也坑了一些人。按直觉和数学知识来看，数字前面的前导0对值应该没有影响。我觉得不如仿照十六进制的形式，使用类似于0o开头作为八进制的语法，在很多新语言里面都是这样的用法。不过C里面为了兼容没法改，这点只能停留在吐槽了吧。数字类型名C中的各种整数类型，除了和八位ASCII码字符类型共用的char之外，都是由零至多个修饰词short，long和类型名int组成的（使用修饰词时可省略int）。另外还有利用long在32位和64位机器上长度不同，用来表示和指针长度相同的整型，这样一个非常不直观的潜规则。其实这些整数类型，除了位数不同（先不考虑正负），没有其他区别。这样的表示法要多记一层对应关系（再考虑32位和64为有不同的对应关系），增加了记忆理解负担，也不方便更大位数的扩展。增加记忆理解负担好理解，为什么说不方便更大数位的扩展呢？看看下面这个蛋疼且无用的推理和那张对应表吧，不想看随便略过。假设我们以后有了128位的计算机（我好像已经看到一些硬件开始支持128位整数了），我们还坚持使用这种类型命名方式，考虑一下整数类型和长度的关系吧。char作为一个ASCII字符，长度8位应该不变吧。现有的32位和64位机器上的类型长度也不能改。还有我们是不是要考虑long和指针等长的惯例，如果推翻这一点，有些兼容性代码就不太容易写出，那假设这一条也成立吧，那么128位上的long就得是128位了。然后从过渡时期开始，64位机器就会支持128位整数吧，那现在long long已经是64位了，128位我们要给个long long long吧，long long long和long long在128位机器上也要有意义，介于long都已经128位了，它们也只能都是128位吧。于是128位机器的long,long long,long long long全成了128位整数。那还剩下16,32,64位的整数我们要在128位机器上表示，但是我们的类型只剩short,int了。那我们要么在char和short中间插入一个short short表示16位；要么推翻long和指针等长的潜规则，让128位机器上的long成为64位。总之在这之前我们应该早就抛弃这种类型命名了。3264128char888short short161616short161632(16)int323264(32)long3264128(64)long long6464128long long long/128128C语言后来的标准也意识到这个问题，引入新的类型别名int8_t,int16_t,int32_t,int64_t,intptr_t等，使用相同的前缀后缀，直接在类姓名中写明长度，而intptr_t顾名思义就是和指针等长的。很多现代语言也采取了这种类型命名方式。这样的类型名能直观地看出每种类型的长度，便于记忆，而且统一，具有扩展性。]]></content>
      <categories>
        <category>吹毛求疵</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rust-1.RAII]]></title>
    <url>%2F2016%2F09%2F25%2Frust-1%2F</url>
    <content type="text"><![CDATA[先来提一下RAII吧，RAII是一种资源管理方式，来源于C++，也是Rust使用的资源管理方式，本篇博文会比较RAII和GC之间的优劣。虽然之前说Rust最重要的设计思想是安全，照理来说我应该把安全相关的特性放开始讲，不过实际上资源释放和安全并没有关系。不过我还是把它放在最前面，因为我觉得RAII和Rust最鲜明的特性所有权系统颇有交叉，而且理解起来更加简单。可能有人会奇怪，资源管理不当会引起内存泄露的，怎么说和安全无关？内存泄露是没有对应该释放的内存进行释放，属于没有对合法的数据进行操作；内存不安全是对不合法的数据进行了操作。所以这是两个性质不同的事情，造成的后果也不一样。内存不安全可能会引起预料之外的输出，断错误等各种bug。内存泄露只是一定程度减少可用内存量。如果内存的泄露是单次而不是持续的，泄露量可控，则一般不会有什么影响；但一次微小的内存不安全操作都可以导致灾难性的后果。当然，内存泄露也不是什么好事，Rust也并不是一不小心就容易造成泄露的语言。只是和100%保证内存安全和线程安全相比，Rust非常耿直地告诉我们，避免内存泄露并不是完全保证的。目前我知道可能导致内存泄露的大概有以下情况:析构函数调用前线程崩溃，导致析构函数没有被调用使用引用计数时，构造了循环引用调用Rust标准库中的forget函数主动泄露什么是RAIIRAII是一种基于栈（或作用域，或固定生命周期）的资源管理方式，广义的RAII可以只是一种惯用法，不过没有语言本身支持，单纯作为惯用法用起来还是很不便的，所以本文讨论的是C++，Rust这样的本身语言有较好支持的狭义RAII。RAII全称是Resource Acquisition Is Initialization，要便于理解的话，或者再加上后半句Resource Reclamation Is Destruction（有人说RAII和RRID是两种相似但不同的方法，对此我不太同意，我觉得就是一个东西）。RAII所作的正如它的全名（包括后半句），资源获取就是初始化，资源释放就是析构；它在变量初始化时，调用构造函数分配资源；在变量析构时，调用析构函数释放其持有的资源。其实在资源管理中，后半句才是关键，因为获取资源是手动的，释放资源是自动的，这里自动的才是有用的特性。绕来绕去说了一大堆，其实简单来讲，一般我们说的RAII就是，在定义对象的时候实现一个析构函数负责释放资源，在变量作用域结束的时候，编译器会自动帮我们加上对析构函数的调用，我们使用这样的对象时，就不需要手动释放资源，从而实现了资源的自动释放。下列代码就是一个简单的例子。1234567891011121314use std::fs::File;use std::io::Write;fn write_to_file(message: &amp;[u8]) &#123; let mut f = File::create("/tmp/test.txt") .expect("Unable to open!"); f.write_all(message) .expect("Unable to write!");&#125;fn main() &#123; write_to_file(b"hello world!");&#125;在这个例子中，程序打开了一个文件，然后在里面写入了&quot;hello world!&quot;，这里说明了RAII的效果，文件/tmp/test.txt在变量f被析构，即在write_to_file函数结束时就被自动关闭了。（expect在创建文件或写入数据失败时使程序直接退出，并输出给定的错误信息，目前可以不用关注)不过这个例子有个不恰当的地方，就是我们不易从现象上判断RAII是否真的生效了，所以下面是另一个例子（所以我干嘛要举上面这个例子）。123456789101112use std::sync::Mutex;fn locked_func(m: &amp;Mutex&lt;()&gt;) &#123; let _lock = m.lock().unwrap();&#125;fn main() &#123; let lock = Mutex::new(()); locked_func(&amp;lock); let _lock = lock.lock().unwrap(); println!("Shouldn't reach here if RAII doesn't work.");&#125;这个程序有一个互斥锁，locked_func函数和main函数都要获取它，如果在locked_func结束时互斥锁没有被释放，则main函数会在获取锁那里被阻塞，程序不会结束，也不会有输出。而实际的行为是相反的，说明我讲的RAII自动释放确实没有骗你们。其实RAII的自动释放不仅作用于函数结束，也可以作用于语句块的结束，上述示例可以简化为如下代码，同样有效。要是删除掉中间那层大括号，程序就会一直卡住，无法结束。12345678910use std::sync::Mutex;fn main() &#123; let mutex = Mutex::new(()); &#123; let _lock = mutex.lock().unwrap(); &#125; let _lock = mutex.lock().unwrap(); println!("Shouldn't reach here if RAII doesn't work.");&#125;返回值优化上面讲的例子中，RAII对资源的自动释放起了很好的效果。但是实际的编程中，我们需要在函数之间传递值。下面，我们来具体谈谈这种情况，RAII这种提倡把内存尽量分配到栈上的内存管理方式，一般这也意味着函数返回时，可能要返回一个很大的结构体。为了更清晰地表达我的意图，这里的某些代码风格可能不太符合Rust的推荐风格。123456789101112struct BigStruct &#123; elm: [u64; 100]&#125;fn rvo_test() -&gt; BigStruct &#123; let res = BigStruct&#123;elm: [0; 100]&#125;; return res;&#125;fn main() &#123; let _bs = rvo_test();&#125;直观理解，在函数rvo_test中，一个大结构BigStruct被创建，保存在局部变量res中，此时BigStruct在rvo_test的栈帧中，然后返回res，函数退出，rvo_test的栈帧以及上面保存在变量res中的BigStruct将被释放；在被释放之前，返回的值赋给main中的局部变量_bs，这个赋值过程一般来看，会有一次内存复制，因为结构比较大，开销也不小，这个内存复制显然是我们想要避免的。一般使用C的编程中，我们会把BigStruct分配到堆上，这样需要返回的值只有一个指针，自然没有这样的内存复制；像java这样的引用类型语言，数据默认被分配在堆上，也没有这个问题。但是我们将BigSturct放在栈里的情况要如何避免这样的复制？考虑到栈后进先出的特性，rvo_test的执行过程中，main的栈帧一定是可用的，不会被释放，这样编译器可以做一个优化，即BigStruct其实只有一份，被分配在main的栈帧里，而在rvo_test函数中对BigStruct的操作，会直接操作main函数栈帧的内存，函数返回自然也无需对其进行复制。这种优化就被称之为返回值优化。返回值优化类似于我们在C里面的一种用法，只是使用更方便自然，编译到机器语言后，基本就是等价的，唯一的区别可能是返回值优化不需要在函数调用时传入指针地址，而是通过栈帧地址减去编译时确定的偏移量计算得到。12345678910111213struct BigStruct &#123; unsigned long long elm[100];&#125;;void rvo_test(struct BigStruct* bs) &#123; *bs = (struct BigStruct)&#123; &#123; 0 &#125; &#125;;&#125;int main(void) &#123; struct BigStruct bs; rvo_test(&amp;bs); return 0;&#125;如果实际上写类似代码，编译去观测其汇编的话，你可能会发现一些更彻底的优化，如：rvo_test函数被内联了，其函数调用都消失了；甚至由于BigStruct的值根本没有被使用，编译器把它们全部去掉，编译出一个空的程序。如果想真正测试返回值优化的效果，可以自行构造更复杂的例子。对RAII这种倾向于把内存分配在栈上的风格来说，返回值优化对性能相当重要；不过返回值优化本身是一个通用优化，对采用值类型的语言都有一定作用（主要使用引用类型的语言应该不太需要）。谈谈GC和RCGC是garbage collection（垃圾回收）的全称，从广义上来讲包含tracing garbage collection和reference counting。其中tracing garbage collection是我们一般见到的GC，从一些引用根开始遍历，标记遍历到的对象，然后将没有标记的释放；而reference counting每新建一个引用，就将对象的引用计数加1，每有一个引用消失，就将计数见减1，引用计数为0时，对象被释放。不过一般我们说GC的时候，是狭义地指tracing garbage collection，也是最常见的GC；而对于reference counting，一般称之为RC。没有特殊指出的话，本文就按照一般的习惯用法，按照狭义理解，分别叫它们GC和RC。GC和RC的对比，其实简直可以另写一篇文章了，所以这里就简单提一下。RC实现非常简单，实时性也好，最后一个引用消失时，立刻就会释放内存，而没有引用遍历的stop the world停顿；但是如果真用最简单直观的方式实现RC，在出现循环引用时会造成内存泄露，多线程时频繁的原子性增减操作会降低运行效率，最后在处理的吞吐量上一般不如GC。大概就讲完了，其实我只是想讲讲GC和RC分别是什么，因为本文其他地方有涉及到，顺便提一提广义上讲它们都是垃圾回收，下面继续讲RAII。RAII的优点RAII相对与GC的优势之一显然是性能和实时性更高，消耗更小，不过这个仅是性能问题，和易用性无关。易用性正如前面所说，RAII能够管理所有种类的资源，而GC只能管理内存。除了内存以外的资源具有唯一性，如我要访问的文件或者申请的同步锁，都是需要特定的那一个；不像内存，只要够用，申请时并不关心具体申请到哪一段。所以内存可以延后统一释放，而具有唯一性的资源必须在使用完毕后立即释放，比如同步锁没有及时释放对整体处理性能的影响是不可接受的；而GC的释放恰恰需要滞后一些的，等累积起来再一起释放。另外RAII与特殊情况下和其他内存管理结合一起使用比较自然，而全局GC则更难和它们兼容。GC对此的变通手段对于内存以外资源的管理，使用GC的语言往往有如下方式进行管理。手动释放加入一些关键词，局部引入RAII（比全局默认的RAII要多写些东西）手动释放自然不用多讲，我们来看看局部引入RAII是什么样的。Python的with关键词123with open('/etc/passwd') as f: for line in f: print(line)Go的defer关键词123456789101112131415161718package mainimport "fmt"import "os"func main() &#123; f := createFile("/tmp/defer.txt") defer f.Close() fmt.Fprintln(f, "data")&#125;func createFile(p string) *os.File &#123; f, err := os.Create(p) if err != nil &#123; panic(err) &#125; return f&#125;吐槽某本Go语言书籍值得一提的是，七牛云出品的《Go语言编程》一书中，有一个有趣的片段，为了说明defer的优点，给出了一段C++作为对比：1234567891011class file_closer &#123; FILE _f;public: file_closer(FILE f): _f(f) &#123; &#125; ~file_closer() &#123; if (f) fclose(f); &#125;&#125;;void f() &#123; FILE f = open_file("file.txt"); file_closer _closer(f);&#125;如此清丽脱俗的例子，C++觉得有一句话它一定要讲。首先是为什么不使用C++标准库里的文件库，一定要使用古老的C文件接口。123void example() &#123; std::ofstream file("example.txt");&#125;正常风格的C++正是使用本篇介绍的RAII，根本不需要任何多余的语句来关闭文件，文件打开的周期就是file变量的生命周期。虽然C++的流式输入输出存在一定问题，不推荐在工业项目中使用，这确实是一个使用C的文件接口的理解。但是其实完全可以进行重新包装，也包装成类似于标准库的风格，由文件类自己管理自己的关闭，而不是独立搞出一个文件关闭类来。其实C++很少有什么功能特性不足，无法写出简短优美的代码这种问题。其最大的问题应该是不能防止某些奇葩程序员写出前面这种奇葩代码来，而这正是Rust在很大程度上可以做到的。小结还有一些语言推荐使用异常处理用的try ... catch ... finally语句模拟类似的效果个人不时很喜欢defer的风格，因为比较而言with对释放资源的时机控制是语句块粒度的，比较精确，可以容易地自己决定资源的有效生命周期，而Go的defer是函数粒度的，必须等到函数结束才自动执行我们的目的是剥离资源释放，使代码主体逻辑更清晰，那对应功能最好专心做这一件事，defer缺少对不合理使用的限制，可以由defer延后执行的不只是资源释放，看起来比较灵活，但这样的使用几乎是任何时候不该使用的错误风格，会使控制流更难分析，可读性下降，这也是goto语句存在的问题。另外这种局部引入RAII的风格相比真正的RAII有个问题是，依旧可能忘写没有释放资源。RAII的缺点RAII的缺陷在于，有些数据的生命周期更加动态，在运行时才能确定，RAII就不太好对它们进行有效的管理。因为运行时才能确定的动态生命周期，要管理它们，必然需要运行时的开销，而RAII没有运行时开销，什么时候释放内存都在编译时决定了。RAII对此的变通手段其实RAII就是无法完全处理这样的情况（蛤？）。所以如果不想手动处理这些内存，那就是需要引入GC（广义的）。不过RAII的一个优势就是，和其他内存管理方式结合使用也非常自然，Rust在这里使用RC进行辅助的内存管理，处理那些生命周期更加动态的资源。（使用需要显式把值包装在具有引用计数的包装类型中）之所以在这里使用RC，我想一是因为RC释放也是立即无延迟的，和RAII比较契合；二是RC比tracing GC的实现简单很多，辅助管理一般不用搞太复杂。不过理论上Rust也可以使用GC，Rust如果有GC，也和Rust的RC使用起来差不多，要显式指明把值放在在通过GC管理的包装类型里。目前已经有人实现了实验性的Rust的GC库，比如rust-gc和mo-gc，虽然尚不足以实际用于生产，但是已经证明了其可行性。总结虽然RAII和GC在不同场景各有优势，RAII也有用起来容易的时候，其实总的来说，易用性还是不如GC。不过采用RAII运行效率高，实时性好，无需虚拟机或嵌入运行时，语言的设计目标是追求速度和系统级编程语言时，选择它也是很自然的事情了（当然手动管理理论效率上限最高，就是写起来麻烦，←_←）。]]></content>
      <categories>
        <category>编程语言安利</category>
        <category>Rust</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>Rust</tag>
        <tag>RAII</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rust-0.概述]]></title>
    <url>%2F2016%2F09%2F25%2Frust-0%2F</url>
    <content type="text"><![CDATA[感觉近几年Go语言很火，不过个人并不喜欢。我个人的意见是，其内部实现非常值得围观学习，但是其作为编程语言的设计实在是惨不忍睹，特别是在21世纪有那么多经验教训可以借鉴的情况下，由Google这么一个名气甚大的公司开发的语言，令人大失所望。按我的判断，近些年的新语言中，最靠谱，最有希望在工业环境大展身手的，就是Rust。故而尝试安利一下。当然我觉得目前的Rust还需要再开发几年才能真正投入实际生产，但是这么有想法的项目在国内关注的人寥寥，不由得有些不平。不过即使在欧美，Rust也属于相对小众，但接触过的人评价都较好的情况，比如可见StackOverflow开发调查2016年的结果和2017年的结果，Rust连续两年在最受喜爱的编程语言中以较大的优势排在第一（因为这个是按百分比比较的），但是从绝对人数来看，Rust并不突出。之后我会按照我认为的语言特性的重要程度的顺序来介绍，并且我会自行脑补这样的设计体现了什么样的思想。因为是安利向的，主要是介绍Rust重要的优点和特点，只要面向已经有编程基础的，说明Rust好在哪里。所以并不准备把语言基本的细节系统地过一遍，有兴趣的可以自行了解。而本篇主要是对Rust语言的总体介绍。另外，知乎上有个Rust编程专栏，我觉得写得不错。我看完之后写出来的文章可能会不自觉地带有里面的有些观点，或自觉地借用一些知识点和例子）。名字由来关于Rust的名字由来，根据道听途说，整理起来大概是这样的。Rust在英语的中意思是腐蚀生锈，很有裸露金属（bare metal）和古老的感觉，而Rust可以编写运行于裸机（bare metal）的程序，同时比较注重吸收其他语言中久经考验的特性，设计上比较复古。另外Rust是Robust（稳健）和Trust（信任）的子串，和Rust注重安全的特性比较契合。设计目标按官方自己的说法，Rust的设计目标是：Safety（安全）Speed（速度）Concurrency（并发）Rust的定位是一门通用的系统编程语言，上面三个设计目标都很好理解。除此之外我们在Rust的设计中还能看到这样的倾向，即主要提供通用的基础设施，故语言核心、核心库和标准库尽量小；并具有足够扩展性，靠近应用层的功能交给库，带着这样的认知，我们看Rust的设计可能更能理解一点。按我的看法呢，速度主要是零开销抽象（zero-cost abstraction），这个大概是来源于C++的思想，主要是虽然提供高层抽象，但尽量不影响最终程序运行的性能，这个思想的影响体现在语言的方方面面，要说起来到处都是，有一些可能不得不对语言本身或库的接口有影响，当然最好还是对使用者透明的优化。而在并发上，Rust把提供并发模型的任务交给了库（可以实现各种不同的并发模型，这得益于Rust良好的扩展性），而Rust拥有独特的机制，保证线程安全，而且这种机制不像某些语言只能用于自带的类型，而是可以提供给所有的用户定义类型，所以自然有很多可安全并发的库。所以依我来看，Rust最核心的设计思想是安全，所以接下来对Rust的介绍也会以安全为核心来介绍。安全，狭义的讲比如内存安全和线程安全；广义上，我觉得可以理解为帮助提高程序的质量。Rust不仅仅做到内存和线程安全，其实也有很多设计可以帮助较少其他的逻辑错误。不追新的设计正如它的名字由来，Rust语言基本没有创造什么崭新酷炫的特性，而是吸收很多已有的经验（当然只用过一些主流语言的人大概会觉得里面有不少新奇的东西）。而且吸收的这些特性都不是Rust的主要卖点，只是借助他们实现自己的目标。对于一些古老的编程语言，里面多多少少的设计失误，Rust也进行了不少合理的微调。要说Rust有什么创新之处的话，我觉得是围绕安全的设计目标，借助一些语言特性，形成对安全问题的整套解决方案。安全的意义安全的好处大家当然都清楚，也不用我赘述，就随便讲个几点：提高代码的正确率，和项目的质量减少程序的调试和测试时间，实际上减少了总体的开发时间安全的代价听说Rust这么厉害，安全又效率，总不能完美无缺，那么代价是什么呢？比如Java也是安全的，付出的代价是运行效率，在运行时增加了完善的安全检查，将不安全的问题转化成了易追踪，易处理的异常。但是静态检查比运行时检查要困难很多，我们可以看到市面上有很多C或者C++的静态分析工具，但都不能完美解决代码的安全问题。这里我们要看看Rust是怎么实现其安全的，如何能够做到C和C++做不到的事情:首先和C++一样，足够高层的抽象能减少不少需要手动实现的琐碎细节，也帮助减少错误。真正重要的是，其实这里非常有意思，即把语义错误（即逻辑错误）转化为语法错误。Rust不像C和C++这么自由，其严格的语法和库接口直接限制了很多可能导致问题的代码无法被编译，而不需要像静态检查工具这样在非常自由的场景下尝试找出逻辑错误。一般编程语言是逻辑没问题的代码一定能编译，但能编译的不一定没问题。Rust则是逻辑没问题的代码不一定能编译通过，但能编译通过的一定不会有安全问题。这其实也是一种思想，即无法解决的问题，其实可以换一条思路，并不解决这个问题本身，而是我们是否真的需要解决这个问题，这个问题本身可能可以简化。不过这样确实带来了一定的问题，就是代码本身的限制增加了，刚开始使用的时候会非常不习惯，可能需要被迫使用一种不同的风格，易用性有些下降，对使用门槛有一定的提高。但是，同时熟练的Rust程序员会更少地遇到与编译检查的冲突（本条凑数）Rust一个重要特性non-lexical lifetimes已经开搞了，这个特性简单来讲就是引入更加智能的生命周期分析，在仍旧保证安全性的前提下，放宽了编译检查的限制，让更多的安全代码成在语法上成为合法的Rust仍然一直努力从各方面提高其易用性安全以外我觉得Rust的相比其他语言的优势在于：相比C，它提供了很多方便的高层抽象相比其他很多同样提供了类似抽象的高级语言，提供了更高的运行速度，并具有直接和底层硬件交互的能力，已经有人用Rust实现了一个操作系统Redox相比C++这样既有高层抽象又有运行效率的语言，其设计更加统一简洁，语法更加严格，减少很多误用和滥用另外我看来Rust的设计具有良好的扩展性：基于trait的面向对象模型（为了解决面向对象的多继承问题，面向对象也有不同的模型，相比与C++机制复杂的多继承和Java功能较弱的interface，trait是一个相当不错的解决方案），利用一些特殊trait可做到运算符重载，自动资源释放，安全并发等利用宏进行编译阶段的代码变换。首先，不同于C的宏，Rust的宏作用在词法分析之后，已经形成token序列，相比C宏的字符串替换，更加严谨和安全；另外除了一般的声明式宏（declartive macro），Rust还有过程式宏（procedural macro），不同于利用特殊语法直观声明变换规则的声明式宏，过程式宏可以看作一个函数，以变换前的代码作为输出，输出变换后的代码，因为在可以直接使用语言的几乎所有功能，我们能够进行比声明式宏自由得多的变换，是一种限制较小的元编程手段。]]></content>
      <categories>
        <category>编程语言安利</category>
        <category>Rust</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>Rust</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客上线第一篇]]></title>
    <url>%2F2016%2F09%2F24%2Ffirst-post%2F</url>
    <content type="text"><![CDATA[作为一个深度拖延症患者，终于还是把博客搭好准备上线了，值得纪念。这个博客主要的目的是，记录一些技术学习后的整理，提升一些逼格（其实并不能），也有可能写些其他有的没的。站点概览里面有我GitHub的链接，里面基本上是空的，大概是由于我对上传代码的要求比较高（其实是没啥拿得出手的东西），加上懒。人活着就是要不断学习。这个博客会成为成长的见证，还是被一个懒鬼废弃在互联网的角落，就让时间来验证吧。目前计划的功能本来这个博客还打算加上更多的功能，不过想想可以以后再说，先把博客上线，把该写的东西发上来才是正经，杂七杂八的功能可以以后慢慢来（安几个hexo插件，改几行配置文件的事，说得好像很麻烦的样子）。大概准备搞的是下面这些，以后完成了会在这里更新一下进度。评论站内搜索阅读量统计酷炫的404页面站点概览太空了，随便加点东西上去先想到这么多，以后有其他想法再说。目前计划的内容其实搭博客之前已经想好很多要写的内容了，等写完这些，可能又有好多想写的东西，不过急也急不来慢慢写吧。基本上现在想好的是下面这些，有内容产出的部分在下面会成为链接。编程语言安利系列Rust编程语言劝退系列GoPerlShell一些奇怪的算法或数据结构的介绍Arch Linux安装及配置系列（也有些Linux通用的东西，会有命令行的使用，但是主要面向用于桌面系统的介绍）Vim(NeoVim)使用及配置系列阅读本博客的注意事项个人风格讲东西喜欢离题，刚好讲到什么可能就顺便介绍一通。博主很菜，看见比较主观的错误观点是正常情况，请温和地指正（等评论功能上线之后（真的会上线吗））。博主很菜，讲的东西一般不会高深；而且因为没有深奥的东西好写，可能会把比较基础的东西讲得比较啰嗦。反正记住博主很菜，你就能理解这个博客的各种不合理之处。]]></content>
      <categories>
        <category>闲言碎语</category>
      </categories>
  </entry>
</search>
